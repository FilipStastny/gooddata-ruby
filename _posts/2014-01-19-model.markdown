---
layout: post
title:  "Creating a data model"
date:   2014-01-19 13:56:00
categories: recipe
next_section: recipe/crunching-numbers
prev_section: recipe/your-first-project
pygments: true
perex: The logical data model (LDM) defines the facts and attributes in your project, as well as their relationships. Let’s have a look at how to create a project’s LDM using Ruby SDK. Then, we compare this method with other approaches.
---

There are several ways to express and create a data model in GoodData. The most prominent way is to use the LDM Modeler, a visual modeler included in the CloudConnect package. The visual approach has clear advantages, but there are some drawbacks.

Visual development is **not repeatable**, **not programmable**, and **not text-based**, which makes it hard to fit into SCM. 

Let's have a look on how to create a simple data model using the Ruby SDK.

##The Data Model

The model we will be creating is the following: ![Model](https://dl.dropboxusercontent.com/s/1y97ziv5anmpn9s/gooddata_devs_demo_model.png?token_hash=AAENC89d8XOfCr9AnyQCrd9vwfhb-bDuYcORQ0AIRP2RQQ). 

The model is briefly discussed in this article: [Your first project](http://sdk.gooddata.com/gooddata-ruby/recipe/your-first-project).

Let's discuss it from a developer's perspective.

##The Code

The easiest way to set up a project from scratch is to use the scaffolding capabilities of the SDK. Execute the following:

{% highlight ruby %}
gooddata scaffold project my_test_project
{% endhighlight %}

Open the file called model/model.rb, and you see the following code:

{% highlight ruby %}
GoodData::Model::ProjectBuilder.create("my_test_project") do |p|
  p.add_date_dimension("committed_on")

  p.add_dataset("repos") do |d|
    d.add_anchor("id")
    d.add_label("name", :reference => "id")
  end

  p.add_dataset("devs") do |d|
    d.add_anchor("id")
    d.add_label("email", :reference => "id")
  end

  p.add_dataset("commits") do |d|
    d.add_fact("lines_changed")
    d.add_date("committed_on", :dataset => "committed_on")
    d.add_reference("dev_id", :dataset => 'devs', :reference => 'id')
    d.add_reference("repo_id", :dataset => 'repos', :reference => 'id')
  end

  p.upload("data/devs.csv", :dataset => 'devs')
  p.upload("data/repos.csv", :dataset => 'repos')
  p.upload("data/commits.csv", :dataset => 'commits')

end
{% endhighlight %}

Hopefully, the above model is fairly self-explanatory. If you need a refresher on modeling terminology such as label and dataset, please refer to [Building a Model in GoodData tutorial](https://developer.gooddata.com/getting-started/).

##Some Conventions

Please note the following rules:

* We are trying to apply conventions to the modeling process. Follow them to reduce the keystrokes. You may always override them.
* In all cases where you enter a name, the value is a **string used to create a technical name in gooddata (an identifier)** using the API. The user-visible name (called the title) will be inferred, if it is not explicitly provided. The inferring process is simple. The Ruby SDK expect you to provide a name in the snake case. Typically in ruby, names like **close_date**, **opportunity_dimension** and more are translated into human-readable strings like **Close date** or **Opportunity dimension**. If you do not like the inferred title, you can specify it directly using code `:title => "My own title"`. 
* Names are also used as reference names in the data model. Notice how the date is using the name of the **close_date** dimension, and the **user_id** reference is used to reference users.

##Executing the model

Execute the model on the platform is just a one-liner:

{% highlight ruby %}
gooddata --username joe@example.com --password my_secret_pass --token my_token project build model.rb
{% endhighlight %}

Since no project_id was provided, a new project is created for us.

##Updating the model

{% highlight ruby %}
gooddata --username joe@example.com --password my_secret_pass --token my_token project update model.rb
{% endhighlight %}

In this case, you must provide a project id in the Goodfile file, and that project's model will be updated. Currently, this updating will **drop cascade all parts of the model**, so be careful. This will be changed in a future release.

##Loading data

As a part of the modeling process, you may load data using it, as some initial datasets should be part of the model, instead of ETL. For example, suppose you are defining reports that are filtered on certain values. These values must be present for the report to work properly.

### Loading data inline

You can load data inline just by adding it to the model file:

{% highlight ruby %}
p.upload([["id", "name"],
          ["1", "Tomas"],
          ["2", "Petr"]], :dataset => 'users')
{% endhighlight %}

### Loading data from a file

Another option is to load data stored in a **csv file**:

{% highlight ruby %}
p.upload("/some/local_file.csv", :dataset => "users")
{% endhighlight %}

### Loading data from a web file

You may also upload data stored in a file on the web:

{% highlight ruby %}
p.upload("http://www.example.com/some/remote_file.csv", :dataset => "users")
{% endhighlight %}

**Remember:** In all cases, the file must contain headers matching the names of the particular columns, although maintaining the same order is not necessary.
